---
title: "Reverse-engineering Claude's sandbox, then building my own"
description: "How Anthropic sandboxes Claude (spoiler: gVisor), and what I learned building a similar system for AI agents."
pubDate: 2025-11-28T18:00:00
tags: ['agents', 'infrastructure', 'security']
---

import Terminal from '../../components/Terminal.astro';
import Browser from '../../components/Browser.astro';
import ClaudeChat from '../../components/ClaudeChat.astro';

A few weeks ago, Anthropic gave Claude filesystem access. If you've used claude.ai recently, you've seen it - Claude can now write files, run Python, execute shell commands.

This wasn't just a feature. It was a bet on how agents should interact with the world.

If you're building an agent, you have two paths. **Path one: tools.** Want the agent to query a database? Build a tool. Search logs? Another tool. Transform data? Tool. Each one needs a schema, validation, error handling. Five actions means five tools. It doesn't scale.

**Path two: give it a terminal.** A bash shell is a meta-tool. One interface, infinite capability. The agent inherits everything the OS offers - Python, grep, awk, curl, the entire unix toolkit. Training data is abundant. The mental model is universal.

Anthropic chose path two. But if you give an agent unlimited OS access, you have a problem: containment. The agent can run arbitrary code. That code might be malicious, buggy, or just resource-hungry.

I was building an agent backend and needed to solve this same problem. Before writing any code, I wanted to see how Anthropic does it.

## Peeking inside Claude's sandbox

Here's the thing about reverse-engineering Claude's sandbox: Claude is the best tool for the job. I can just ask it to inspect its own environment.

<Browser url="claude.ai" title="Claude">
  <ClaudeChat
    initials="ML"
    maxHeight="600px"
    messages={[
      { role: 'human', text: 'What kernel are you running on?' },
      { role: 'assistant', content: [
        { tool: 'Check kernel version', command: 'uname -a', output: 'Linux runsc 4.4.0 #1 SMP Sun Jan 10 15:06:54 PST 2016 x86_64 GNU/Linux' },
        "The `runsc` hostname and 2016 date are gVisor's signature. I'm running in a gVisor sandbox, not a regular container or VM."
      ]},
      { role: 'human', text: 'What are your resource limits?' },
      { role: 'assistant', content: [
        { tool: 'Check resource limits', command: 'free -h && nproc', output: `              total   used    free
Mem:          9.0Gi   11Mi   9.0Gi

4` },
        "9GB memory, 4 CPUs. Generous for a sandbox."
      ]},
      { role: 'human', text: 'How does network access work?' },
      { role: 'assistant', content: [
        { tool: 'Check network config', command: "echo $HTTP_PROXY", output: 'http://container_xxx:jwt_eyJ0eXAiOiJKV1QiLC...@21.0.0.15:15004' },
        "All traffic goes through a proxy. The credentials are a JWT. Let me decode it."
      ]},
      { role: 'human', text: 'What\'s in the JWT?' },
      { role: 'assistant', content: [
        { tool: 'Decode JWT payload', command: 'echo $HTTP_PROXY | grep -oP "jwt_\\K[^@]+" | cut -d. -f2 | base64 -d | python3 -m json.tool', output: `{
    "iss": "anthropic-egress-control",
    "allowed_hosts": "github.com,pypi.org,npmjs.org,crates.io,api.anthropic.com,...",
    "exp": 1764386514
}` },
        "The proxy only allows traffic to package registries, GitHub, and Anthropic's API. The token expires in 4 hours. Network access exists, but it's tightly controlled."
      ]},
      { role: 'human', text: "What's running as PID 1?" },
      { role: 'assistant', content: [
        { tool: 'Check init process', command: 'ps aux | head -2', output: `USER  PID  COMMAND
root    1  /process_api --addr 0.0.0.0:2024 --memory-limit-bytes 4294967296` },
        "PID 1 is a custom binary - not bash, not systemd. It's listening on port 2024 and enforcing a 4GB memory limit. This is the agent executor that spawns shells for each command."
      ]}
    ]}
  />
</Browser>

This revealed more than I expected.

**Network control via egress proxy.** Instead of disabling network entirely, all traffic routes through a proxy that validates JWTs. The token contains an allowlist of hosts (package registries, GitHub, Anthropic API) and expires in 4 hours. Claude has network access - it's just tightly controlled.

**A custom init process.** PID 1 isn't a shell - it's `/process_api`, a purpose-built binary that receives commands and enforces resource limits at the application layer.

**Running as root inside the sandbox.** This surprised me. gVisor's isolation is strong enough that they don't bother with a non-root user.

| What I expected | What I found |
|----------------|--------------|
| No network | JWT-authenticated egress proxy |
| Shell as PID 1 | Custom `/process_api` binary |
| Non-root user | Root (uid=0) |

The image is ~7GB with ffmpeg, ImageMagick, LaTeX, Playwright, LibreOffice - everything for file processing. For my use case, a minimal ~200MB image is enough.

## The options

**Firecracker** is what AWS uses for Lambda. MicroVMs that boot in ~125ms with ~5MB memory overhead. True VM-level isolation. The catch: it needs direct KVM access. Standard Kubernetes nodes are themselves VMs - Firecracker won't run inside them without bare metal instances. Operationally complex.

**gVisor** intercepts syscalls in userspace. Your container gets its own "kernel" - really a Go program pretending to be a kernel. It works anywhere Docker runs. Google uses this for Cloud Run and GKE Sandbox. Simpler to operate, slightly more syscall overhead.

**Plain Docker** shares the kernel with the host. Container escapes are rare but real. For untrusted code, that's not enough.

Anthropic chose gVisor. So did I.

## The sandbox image

First, what goes in the container:

```dockerfile
FROM python:3.13-slim-bookworm

RUN apt-get update && apt-get install -y --no-install-recommends \
    coreutils grep sed gawk findutils \
    curl wget git jq tree vim-tiny less procps \
    && rm -rf /var/lib/apt/lists/*

RUN mkdir -p /mnt/user-data/uploads \
             /mnt/user-data/outputs \
             /workspace

WORKDIR /workspace

CMD ["tail", "-f", "/dev/null"]
```

Python, standard unix utils, and a directory structure that mirrors Claude's. No non-root user - gVisor provides the isolation boundary, not Linux permissions. The `tail -f /dev/null` keeps the container alive; in production you'd replace this with a proper init process like Claude's `/process_api`.

## Container lifecycle

Three options for when containers live and die:

**Pre-warmed pool**: Keep N containers running idle, grab one when needed. ~10-50ms latency. But you're managing a pool, handling assignment, dealing with cleanup. Complex.

**Per-execution**: New container for each command. Simplest code. ~600ms-1.2s cold start every time. Too slow.

**Session-scoped**: Container lives for the user session. Cold start once, then instant for every subsequent execution.

I went with session-scoped. The initial cold start (~800ms) hides behind LLM inference anyway - users are already waiting for the agent to think. By the time it responds, the container is warm.

```python
class SandboxManager:
    def __init__(self, image_name: str, runtime: str = "runsc", storage_path: Path = None):
        self.client = docker.from_env()
        self.image_name = image_name
        self.runtime = runtime
        self.storage_path = storage_path
        self.sessions: dict[str, SandboxSession] = {}

    async def create_session(self, session_id: str, tenant_id: str):
        tenant_dir = self.storage_path / tenant_id
        (tenant_dir / "workspace").mkdir(parents=True, exist_ok=True)
        (tenant_dir / "outputs").mkdir(parents=True, exist_ok=True)

        container = self.client.containers.run(
            self.image_name,
            detach=True,
            name=f"sandbox-{session_id[:8]}",
            runtime=self.runtime,
            mem_limit="4g",
            cpu_period=100000,
            cpu_quota=400000,  # 4 CPUs
            environment={
                "HTTP_PROXY": self._generate_proxy_url(session_id, tenant_id),
                "HTTPS_PROXY": self._generate_proxy_url(session_id, tenant_id),
            },
            volumes={
                str(tenant_dir / "workspace"): {"bind": "/workspace", "mode": "rw"},
                str(tenant_dir / "outputs"): {"bind": "/mnt/user-data/outputs", "mode": "rw"},
            },
        )

        self.sessions[session_id] = SandboxSession(session_id, container, tenant_id)
        return container
```

The key insight from Claude's architecture: network isn't disabled, it's controlled. All traffic routes through an egress proxy that validates requests against an allowlist.

## Defense in depth

Four layers of isolation:

**gVisor runtime** - The primary boundary. Syscalls are intercepted by a userspace kernel written in Go. Even if code escapes the container, it's running against gVisor, not your host. This is why Claude can run as root - "root" inside gVisor has no privileges outside it.

**Egress proxy with allowlist** - All outbound traffic routes through a proxy that validates requests. The sandbox can reach pypi.org, github.com, npm - but nothing else. No exfiltration to arbitrary hosts. The proxy authenticates requests with short-lived JWTs that encode the allowed hosts.

**Resource limits** - 4GB memory, 4 CPUs. A runaway process can't starve the host. The init process can enforce additional limits at the application layer.

**Filesystem mounts** - Only `/workspace` and `/mnt/user-data/outputs` are writable. User uploads mount read-only. The sandbox can't modify its own image or persist changes outside designated paths.

## The egress proxy

The egress proxy is the clever part of this architecture. Instead of disabling network and dealing with the pain of `pip install`, you control *where* traffic can go.

The proxy validates each request against an allowlist encoded in a JWT:

```python
def _generate_proxy_url(self, session_id: str, tenant_id: str) -> str:
    payload = {
        "iss": "sandbox-egress-control",
        "session_id": session_id,
        "tenant_id": tenant_id,
        "allowed_hosts": [
            "pypi.org", "files.pythonhosted.org",  # pip
            "registry.npmjs.org",                   # npm
            "github.com",                           # git clone
        ],
        "exp": datetime.utcnow() + timedelta(hours=4),
    }
    token = jwt.encode(payload, self.signing_key, algorithm="ES256")
    return f"http://sandbox:{token}@{self.proxy_host}:{self.proxy_port}"
```

The proxy (a simple HTTP CONNECT proxy with JWT validation) checks each request:

```python
async def handle_connect(self, request):
    token = extract_token_from_auth(request)
    payload = jwt.decode(token, self.public_key, algorithms=["ES256"])

    target_host = request.url.host
    if target_host not in payload["allowed_hosts"]:
        return Response(status=403, text=f"Host not allowed: {target_host}")

    # Proxy the connection...
```

This solves the pip problem elegantly. The agent can `pip install requests` because pypi.org is in the allowlist. But it can't exfiltrate data to evil.com.

## Streaming output

Users want to see output as it happens, not wait for completion. Docker's exec API supports streaming:

```python
async def exec_stream(self, session_id: str, command: str, workdir: str = "/workspace"):
    session = self.sessions.get(session_id)
    container = session.container

    exec_instance = container.client.api.exec_create(
        container.id,
        cmd=["bash", "-c", command],
        workdir=workdir,
        stdout=True,
        stderr=True,
    )

    output = container.client.api.exec_start(exec_instance["Id"], stream=True, demux=True)

    for stdout_chunk, stderr_chunk in output:
        if stdout_chunk:
            yield {"type": "stdout", "data": stdout_chunk.decode("utf-8")}
        if stderr_chunk:
            yield {"type": "stderr", "data": stderr_chunk.decode("utf-8")}

    exec_info = container.client.api.exec_inspect(exec_instance["Id"])
    yield {"type": "exit", "code": exec_info["ExitCode"]}
```

The `demux=True` separates stdout and stderr. Without it, you get interleaved output and can't tell which is which.

## What it looks like from inside

<Terminal title="sandbox-abc123" maxHeight="none">
  <div class="sandbox-demo">
    <div class="cmd-line">
      <span class="prompt">$</span>
      <span class="cmd">uname -r</span>
    </div>
    <div class="output">4.4.0 runsc</div>
    <div class="annotation">gVisor, not host kernel</div>

    <div class="cmd-line">
      <span class="prompt">$</span>
      <span class="cmd">whoami</span>
    </div>
    <div class="output">root</div>
    <div class="annotation">root inside sandbox, no privileges outside</div>

    <div class="cmd-line">
      <span class="prompt">$</span>
      <span class="cmd">curl https://pypi.org</span>
    </div>
    <div class="output">HTTP/1.1 200 OK</div>
    <div class="annotation">allowlisted host works</div>

    <div class="cmd-line">
      <span class="prompt">$</span>
      <span class="cmd">curl https://evil.com</span>
    </div>
    <div class="output error">HTTP/1.1 403 Forbidden - Host not allowed</div>
    <div class="annotation">egress proxy blocks unlisted hosts</div>

    <div class="cmd-line">
      <span class="prompt">$</span>
      <span class="cmd">ls /</span>
    </div>
    <div class="output">workspace  mnt  usr  bin  ...</div>
    <div class="annotation">full filesystem, writes restricted to /workspace</div>

    <div class="mount-info">
      <span class="arrow">↓</span>
      <span class="mount-text">/workspace mounts to /data/tenants/{`{id}`}/workspace on host</span>
    </div>
  </div>
</Terminal>

<style>{`
  .sandbox-demo {
    font-family: "SF Mono", Consolas, "Liberation Mono", Menlo, monospace;
    font-size: 13px;
    line-height: 1.6;
  }
  .cmd-line {
    margin-top: 8px;
  }
  .cmd-line:first-child {
    margin-top: 0;
  }
  .prompt {
    color: #4ec9b0;
    margin-right: 8px;
  }
  .cmd {
    color: #e0e0e0;
  }
  .output {
    color: #9cdcfe;
    margin-left: 16px;
  }
  .output.error {
    color: #f48771;
  }
  .annotation {
    color: #6a9955;
    font-style: italic;
    margin-left: 16px;
    font-size: 12px;
  }
  .annotation::before {
    content: "← ";
    color: #555;
  }
  .mount-info {
    margin-top: 16px;
    padding-top: 12px;
    border-top: 1px solid #333;
    color: #888;
    font-size: 12px;
  }
  .arrow {
    color: #569cd6;
    margin-right: 8px;
  }
`}</style>

## Trade-offs I accepted

**No container pooling.** Pre-warmed pools give you ~10-50ms latency instead of ~800ms. But session-scoped is simpler and the cold start hides behind LLM inference. I'll add pooling when latency actually becomes a problem.

**No snapshot/restore.** Firecracker can snapshot a running VM and restore in ~5ms. gVisor doesn't support this. If I ever need sub-second container startup, I'll revisit Firecracker and accept the operational complexity.

**Egress proxy is another service to run.** The JWT-based proxy adds infrastructure. For a simple setup, `network_mode: none` is easier. But it's worth it - agents that can't pip install are significantly less useful.

**gVisor's syscall overhead.** Some workloads see 2-10x slowdown on syscall-heavy operations. For "run Python scripts and shell commands" this is negligible. For high-frequency I/O, you'd notice.

**No GPU support.** gVisor has experimental GPU passthrough, but I haven't needed it. When I do, this gets more complicated.

## The punchline

Firecracker is technically superior. Faster boot, true VM isolation, snapshot/restore. But it requires KVM access, which means bare metal or nested virtualization. For most teams running on standard cloud infrastructure, that's a non-starter.

gVisor is the practical choice. It works in standard Kubernetes, standard Docker, anywhere containers run. Google trusts it for Cloud Run. Anthropic trusts it for Claude. The isolation is strong enough to run as root inside the sandbox.

The pattern I learned from reverse-engineering Claude's sandbox: gVisor as the hard security boundary, an egress proxy for network control instead of disabling it entirely, and session-scoped containers that hide cold start behind LLM inference latency.

If you're building agents that execute code, you need something like this. The alternative - running untrusted code on your host - is not an option.
